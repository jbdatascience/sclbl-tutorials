{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exploring training vs. deployment requirements\n",
    "> 20-10-2020\n",
    "\n",
    "In this notebook we illustrate the differences between model training and model deployment in a bit more depth, using a simple logistic regression model as an example. This notebook accompanies the following Medium post: [Exploiting the differences between model training and prediction](https://medium.com/p/40f087e52923/)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "> The code accompanying the section on **Model training**\n",
    "\n",
    "---\n",
    "\n",
    "### Data generation\n",
    "We start by generating some data that we can use to fit our example logistic regression model to. The code below generates 1000 observations according to the following simple model:\n",
    "\n",
    "$Pr(y = 1 | x) = \\frac{1}{1 + e^{-1(.75 + 1.5x_1 -.5x_2)}}$.\n",
    "\n",
    "Thus, we have a simple logistic model with two features and parameters $\\beta_0 = .75$ (intercept), $\\beta_1 = 1.5$, and $\\beta_2=-.5$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-1.38284969  0.11827429  0.        ]\n",
      " [-1.46520176  1.97455925  0.        ]\n",
      " [-0.54925814 -0.84398759  0.        ]\n",
      " [ 0.7164355   1.84642289  0.        ]\n",
      " [-1.22219977  0.07416729  0.        ]\n",
      " [-0.99515847 -0.08198656  0.        ]\n",
      " [ 1.03366557 -0.42144807  1.        ]\n",
      " [ 0.23047436  1.66806784  1.        ]\n",
      " [ 0.05921167 -0.63964774  1.        ]\n",
      " [-0.12880055  1.93380488  1.        ]]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "np.random.seed(66)  # Set seed for replication\n",
    "\n",
    "# Simulate Data Generating Process\n",
    "n = 1000  # 1000 observations\n",
    "x1 = np.random.uniform(-2,2,n)  # x_1 & x_2 between -2 and 2\n",
    "x2 = np.random.uniform(-2,2,n)\n",
    "p = 1 / (1 + np.exp( -1*(.75 + 1.5*x1 - .5*x2) ))  # Implement DGP\n",
    "\n",
    "y = np.random.binomial(1, p, n)  # Draw outcomes\n",
    "\n",
    "# Create dataset and print first few lines:\n",
    "data = np.column_stack((x1,x2,y))\n",
    "print(data[:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model training\n",
    "After generating the example data, we can fit the model. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression  # import sklearn LogisticRegression\n",
    "\n",
    "# Fit the model\n",
    "mod = LogisticRegression().fit(data[:,[0,1]], np.ravel(data[:,[2]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The number of iterations is: [7].\n"
     ]
    }
   ],
   "source": [
    "# Print the number of iterations\n",
    "print(f'The number of iterations is: {mod.n_iter_}.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "> The code accompanying the section on Generating predictions\n",
    "---\n",
    "\n",
    "### Inspecting the fitted model\n",
    "We inspect the fitted model parameters and the number of iterations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitted model parameters: [ 0.84576563  1.39541631 -0.47393112].\n"
     ]
    }
   ],
   "source": [
    "# Retrieve the fitted model parameters:\n",
    "b = np.concatenate((mod.intercept_, mod.coef_.flatten()))\n",
    "\n",
    "print(f'Fitted model parameters: {b}.')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "> The code accompanying the section called Exploiting the differences for (edge) deployment\n",
    "---\n",
    "### Inspecting the sizes of various objects.\n",
    "Here we inspect the sizes of various of the generated objects. Note that we use the `get_size` function as [introduced in this post](https://goshippo.com/blog/measure-real-size-any-python-object/)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of the dataset: 24496.\n",
      "Size of the model: 2424.\n",
      "Size of the cofficients: 216.\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "\n",
    "def get_size(obj, seen=None):\n",
    "    \"\"\"Recursively finds size of objects\"\"\"\n",
    "    size = sys.getsizeof(obj)\n",
    "    if seen is None:\n",
    "        seen = set()\n",
    "    obj_id = id(obj)\n",
    "    if obj_id in seen:\n",
    "        return 0\n",
    "    # Important mark as seen *before* entering recursion to gracefully handle\n",
    "    # self-referential objects\n",
    "    seen.add(obj_id)\n",
    "    if isinstance(obj, dict):\n",
    "        size += sum([get_size(v, seen) for v in obj.values()])\n",
    "        size += sum([get_size(k, seen) for k in obj.keys()])\n",
    "    elif hasattr(obj, '__dict__'):\n",
    "        size += get_size(obj.__dict__, seen)\n",
    "    elif hasattr(obj, '__iter__') and not isinstance(obj, (str, bytes, bytearray)):\n",
    "        size += sum([get_size(i, seen) for i in obj])\n",
    "    return size\n",
    "\n",
    "\n",
    "print(f'Size of the dataset: {get_size(data)}.')\n",
    "print(f'Size of the model: {get_size(mod)}.')\n",
    "print(f'Size of the cofficients: {get_size(b)}.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of the pickled model object: 841.\n"
     ]
    }
   ],
   "source": [
    "# Use pickle to store the model\n",
    "import pickle\n",
    "s = pickle.dumps(mod)\n",
    "\n",
    "# Dump the object\n",
    "pickle.dump(mod, open( \"model.pickle\", \"wb\" ))\n",
    "\n",
    "print(f'Size of the pickled model object: {get_size(s)}.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Converting the model to WebAssembly\n",
    "The code to convert the fitted model to a WebAssembly binary using the [sclblpy](https://pypi.org/project/sclblpy/) package."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sclblpy as sp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: You did not provide any documentation. \n",
      "We will simply use LogisticRegression as its name without further documentation.\n",
      "Your model was successfully uploaded to Scailable!\n",
      "NOTE: After transpiling, we will send you an email and your model will be available at https://admin.sclbl.net.\n",
      "Or, alternatively, you can use the 'endpoints()' function to list all your uploaded models. \n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "row = np.array([1,1])  # Example feature vector\n",
    "\n",
    "# Upload the model to convert to .WASM (note, no documentation uploaded)\n",
    "sp.upload(mod, row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You currently own the following endpoints:\n",
      "\n",
      "  1: LogisticRegression, \n",
      "   - cfid: 9cd6ecd0-12e3-11eb-8eec-9600004e79cc \n",
      "   - example: https://admin.sclbl.net/run.html?cfid=9cd6ecd0-12e3-11eb-8eec-9600004e79cc&exin=%5B%5B1%2C%201%5D%5D \n",
      "\n",
      "  2: Add - for js client, \n",
      "   - cfid: 27d21872-c4ff-11ea-816c-9600004e79cc \n",
      "   - example: https://admin.sclbl.net/run.html?cfid=27d21872-c4ff-11ea-816c-9600004e79cc&exin=%5B1%2C2%2C3%2C4%5D \n",
      "\n",
      "  3: Simple linear regression demo, \n",
      "   - cfid: e871d8e5-b2e2-11ea-a47d-9600004e79cc \n",
      "   - example: https://admin.sclbl.net/run.html?cfid=e871d8e5-b2e2-11ea-a47d-9600004e79cc&exin=%5B%5B2%2C%205%5D%5D \n",
      "\n",
      "  4: XGBoost breast cancer model, \n",
      "   - cfid: 007bdbaa-b093-11ea-a47d-9600004e79cc \n",
      "   - example: https://admin.sclbl.net/run.html?cfid=007bdbaa-b093-11ea-a47d-9600004e79cc&exin=%5B%5B17.99%2C%2010.38%2C%20122.8%2C%201001.0%2C%200.1184%2C%200.2776%2C%200.3001%2C%200.1471%2C%200.2419%2C%200.07871%2C%201.095%2C%200.9053%2C%208.589%2C%20153.4%2C%200.006399%2C%200.04904%2C%200.05373%2C%200.01587%2C%200.03003%2C%200.006193%2C%2025.38%2C%2017.33%2C%20184.6%2C%202019.0%2C%200.1622%2C%200.6656%2C%200.7119%2C%200.2654%2C%200.4601%2C%200.1189%5D%5D \n",
      "\n",
      "  5: Simple linear regression demo, \n",
      "   - cfid: 97ae1d0b-aee8-11ea-a47d-9600004e79cc \n",
      "   - example: https://admin.sclbl.net/run.html?cfid=97ae1d0b-aee8-11ea-a47d-9600004e79cc&exin=%5B%5B20%5D%5D \n",
      "\n",
      "Login at https://admin.sclbl.net to administer your endpoints and see integration examples.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# After uploading, inspect the results\n",
    "ep = sp.endpoints()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1.76725083]\n"
     ]
    }
   ],
   "source": [
    "# The output produced by the Scailable .WASM\n",
    "result = mod.decision_function(row.reshape(1,-1))\n",
    "print(result) ## This is the output created by the Scailable .WASM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> **Note:** The prediction is not the class label but rather the output of the `decision_function()`. See the [`sklearn` documentation](https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LogisticRegression.html#sklearn.linear_model.LogisticRegression.decision_function) for details. If the output is $>0$, the label $1$ is predicted."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Consuming the REST endpoint\n",
    "To wrap up: the REST endpoint running the deployed WebAssembly model can be tester [here](https://admin.sclbl.net/run.html?cfid=9cd6ecd0-12e3-11eb-8eec-9600004e79cc&exin=%5B%5B1%2C%201%5D%5D). Note that the generated .WASM executable can be downloaded [here](https://cdn.sclbl.net:8000/file/9cd6ecd0-12e3-11eb-8eec-9600004e79cc.wasm)."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
