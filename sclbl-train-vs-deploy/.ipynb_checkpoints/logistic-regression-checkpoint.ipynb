{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exploring training vs. deployment requirements\n",
    "> 19-10-2020\n",
    "\n",
    "In this notebook we illustrate the differences between model training and model deployment in a bit more depth, using a simple logistic regression model as an example."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The data\n",
    "We start by generating some data that we can use to fit our example logistic regression model to. The code below generates 1000 observations according to the following simple model:\n",
    "\n",
    "$Pr(y = 1 | x) = \\frac{1}{1 + e^{-1(.75 + 1.5x_1 -.5x_2)}}$.\n",
    "\n",
    "Thus, we have $\\beta_0 = .75$, $\\beta_1 = 1.5$, and $\\beta_2=-.5$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.21699199  1.70626983  0.        ]\n",
      " [ 0.33088623  0.31927093  1.        ]\n",
      " [ 0.42139769 -0.56196383  1.        ]\n",
      " [ 1.62725099  1.67986145  1.        ]\n",
      " [-0.0407933  -0.53697263  1.        ]\n",
      " [-1.29861553  0.08937192  0.        ]\n",
      " [ 0.78383487  1.43907342  1.        ]\n",
      " [ 1.27006773  0.05205827  1.        ]\n",
      " [-1.03640642 -0.81844398  0.        ]\n",
      " [-1.73163517  1.64711652  0.        ]]\n",
      "[[ 0.21699199  1.70626983]\n",
      " [ 0.33088623  0.31927093]\n",
      " [ 0.42139769 -0.56196383]\n",
      " ...\n",
      " [-1.30713503 -0.84853104]\n",
      " [-0.35355419  1.11673014]\n",
      " [ 0.02514672  0.41085014]]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Simulate Data Generating Process\n",
    "n = 1000  # 1000 observations\n",
    "x1 = np.random.uniform(-2,2,n)  # x_1 & x_2 between -2 and 2\n",
    "x2 = np.random.uniform(-2,2,n)\n",
    "p = 1 / (1 + np.exp( -1*(.75 + 1.5*x1 - .5*x2) ))  # Implement DGP\n",
    "\n",
    "y = np.random.binomial(1, p, n)  # Draw outcomes\n",
    "\n",
    "# Create dataset and print first few lines:\n",
    "data = np.column_stack((x1,x2,y))\n",
    "print(data[:10])\n",
    "\n",
    "print(data[:,[0,1]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fitting the model\n",
    "After generating the example data, we can fit the model. Note that we print the iterations of the model to make explicit how the training is carried out."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "mod = LogisticRegression().fit(data[:,[0,1]], np.ravel(data[:,[2]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.7911692   1.58688224 -0.45307928]\n",
      "[8]\n"
     ]
    }
   ],
   "source": [
    "b = np.concatenate((mod.intercept_, mod.coef_.flatten()))\n",
    "\n",
    "print(b)\n",
    "print(mod.n_iter_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24496\n",
      "2424\n",
      "216\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "\n",
    "def get_size(obj, seen=None):\n",
    "    \"\"\"Recursively finds size of objects\"\"\"\n",
    "    size = sys.getsizeof(obj)\n",
    "    if seen is None:\n",
    "        seen = set()\n",
    "    obj_id = id(obj)\n",
    "    if obj_id in seen:\n",
    "        return 0\n",
    "    # Important mark as seen *before* entering recursion to gracefully handle\n",
    "    # self-referential objects\n",
    "    seen.add(obj_id)\n",
    "    if isinstance(obj, dict):\n",
    "        size += sum([get_size(v, seen) for v in obj.values()])\n",
    "        size += sum([get_size(k, seen) for k in obj.keys()])\n",
    "    elif hasattr(obj, '__dict__'):\n",
    "        size += get_size(obj.__dict__, seen)\n",
    "    elif hasattr(obj, '__iter__') and not isinstance(obj, (str, bytes, bytearray)):\n",
    "        size += sum([get_size(i, seen) for i in obj])\n",
    "    return size\n",
    "\n",
    "print(get_size(data))\n",
    "print(get_size(mod))\n",
    "print(get_size(b))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "841\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "s = pickle.dumps(mod)\n",
    "\n",
    "print(get_size(s))\n",
    "\n",
    "pickle.dump(mod, open( \"model.pickle\", \"wb\" ) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "*** Thanks for importing sclblpy! ***\n",
      "You can use the 'upload()' function to upload your models.\n",
      "To inspect your currently uploaded models, use `endpoints()`.\n",
      "Check the docs at https://pypi.org/project/sclblpy/ for more info. \n",
      "\n"
     ]
    }
   ],
   "source": [
    "import sclblpy as sp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "upload() missing 1 required positional argument: 'feature_vector'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-55-8699ac696426>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0msp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmod\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m: upload() missing 1 required positional argument: 'feature_vector'"
     ]
    }
   ],
   "source": [
    "sp.upload(mod)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Your stored user credentials have been removed. \n",
      "You will have to re-enter your username and password next time.\n",
      "Successfully removed your user credentials.\n",
      "WARNING: You did not provide any documentation. \n",
      "We will simply use LogisticRegression as its name without further documentation.\n",
      "Please provide your username: maurits.kaptein@scailable.net\n",
      "Please type your password: ········\n",
      "Would you like us to store your user credentials (y/n)? y\n",
      "Your model was successfully uploaded to Scailable!\n",
      "NOTE: After transpiling, we will send you an email and your model will be available at https://admin.sclbl.net.\n",
      "Or, alternatively, you can use the 'endpoints()' function to list all your uploaded models. \n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "row = np.array([1,1])\n",
    "sp.upload(mod, row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "fv = np.array([0,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0])"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
